# DeGauss: Dynamic-Static Decomposition with Gaussian Splatting for Distractor-free 3D Reconstruction

## ICCV 2025

### [Project Page](https://batfacewayne.github.io/DeGauss.io/)| [arXiv Paper](https://arxiv.org/abs/2503.13176) | [Youtube](https://www.youtube.com/watch?v=d8U4--_jIcc) | [HuggingFace Model](https://huggingface.co/BatofGo/DeGauss_ckpts/tree/main)

[Rui Wang](https://pdz.ethz.ch/the-group/people/rui-wang.html) [Quentin Lohmeyer](https://pdz.ethz.ch/the-group/people/lohmeyer.html) [Mirko Meboldt](https://pdz.ethz.ch/the-group/people/meboldt.html) [Siyu Tang](https://vlg.ethz.ch/team/Prof-Dr-Siyu-Tang.html)

ETH Zurich


---

![Teaser GIF](assets/teaser.gif)

Our method achieves fastâš¡ï¸ and robustâ›·ï¸ dynamic-static decomposition based on gaussian splatting.


## News

2025.7.31: Initial Code Release

## Environmental Setups
Clone the repo and 

```bash
git clone git@github.com:BatFaceWayne/DeGauss.git
cd DeGauss
git submodule update --init --recursive
```

The environment fully compatitable with [4DGaussians](https://github.com/hustvl/4DGaussians). If you have that environment prepared you could skip this step. Alternatively you could prepare the environment as follows

```bash
conda create -n DeGauss python=3.11
conda activate DeGauss

pip install -r requirements.txt
pip install -e submodules/depth-diff-gaussian-rasterization
pip install -e submodules/simple-knn
```

## Data Preparation
Please follow the instructions in [4DGaussians](https://github.com/hustvl/4DGaussians) for Neu3D and HyperNerf dataset preparation, and [SpotLessSplats](https://github.com/lilygoli/SpotLessSplats/tree/main) for RobustNerf and Nerf on-the-go dataset processing. For Aria Datasets, please refer to [project-aria](https://www.projectaria.com/resources/#resources-datasets) and prepare data with [Nerfstudio](https://docs.nerf.studio/quickstart/custom_dataset.html#aria). The EPIC-Field dataset could be accessed [here](https://epic-kitchens.github.io/epic-fields/).


The dataset structureshould look follows

```
â”œâ”€â”€ data
â”‚   | hypernerf
â”‚     â”œâ”€â”€ interp
â”‚     â”œâ”€â”€ misc
â”‚     â”œâ”€â”€ virg
â”‚   | dynerf
â”‚     â”œâ”€â”€ cook_spinach
â”‚       â”œâ”€â”€ cam00
â”‚           â”œâ”€â”€ images
â”‚               â”œâ”€â”€ 0000.png
â”‚               â”œâ”€â”€ 0001.png
â”‚               â”œâ”€â”€ 0002.png
â”‚               â”œâ”€â”€ ...
â”‚     ...
|  | Nerf on-the-go/RobustNerf
|     â”œâ”€â”€ fountain
â”‚       â”œâ”€â”€ images
â”‚           â”œâ”€â”€ 1extra000.JPG
|           ...
â”‚           â”œâ”€â”€ 2clutter008.JPG
|           ...
|     â”œâ”€â”€ mountain
|     ...
|  | Aria Digital Twin /Aria Everyday Activities / Hot3D
|     â”œâ”€â”€ Seq1
â”‚       â”œâ”€â”€ images
â”‚       â”œâ”€â”€ masks
â”‚       |__ global_points.ply
|     ...

```
### Dataset processing
Note: The camera poses in [HyperNeRF](https://github.com/google/hypernerf) are rather inaccurate, as pointed out in [previous work](https://github.com/CVMI-Lab/SC-GS). Therefore we adopted colmap for pose estimation and only used this dataset for qualitative comparison. You could find the example of prepared Vrig-cheicken scene [here](https://drive.google.com/file/d/1BoWvcSuQlGLdaO8iQIPuJFhiL1RldYhs/view?usp=drive_link).

### Todo
- release detailed scripts pre-processing aria datasets.
## Checkpoints and Renders ğŸ”¥
To promote reproducibility, we have released our gaussian models, Full render and dynamic-static decomposition renders of Nerf on-the-go dataset, RobustNerf dataset and Neu3D dataset at [Checkpoints & Renders](https://huggingface.co/BatofGo/DeGauss_ckpts/tree/main). 

To visualize gaussian models, we recommend using this amazing gaussian splatting visualizing tool: [online visualizer](https://antimatter15.com/splat/).

## Training


For training video datasets as  `cut_roasted_beef` of Neu3D dataset, run
```python
##### please refer to the configs in folder arguments for different dataset setup
python train.py -s data/dynerf/cut_roasted_beef --port 6019 --expname cut_roasted_beef --configs arguments/video_dataset/Neu3D.py
```

For training image datasets for distractor-free scene modeling as Neu3D scenes such as `cut_roasted_beef`, run
```python
######## please use configs nerfonthego.py for indoor scenes
python3 train.py -s data/nerf-on-the-go/mountain --port 6019 --expname mountain --configs arguments/image_dataset/nerfonthego_outdoor.py
```
### Custom datasets
We have tested our method for various datasets, as reported in our paper. For customized dataset, simply prepare the input with colmap. And refer to the detailed hint in the arguments/video_dataset/default.py for parameters set-up.You can customize your training config through the config files.


## Rendering

Run the following script to render Neu3D dataset.
```python
######## please use configs nerfonthego.py for indoor scenes
python render_gaussian_dynerf.py -s path_to_dataset --port 6017 --expname Neu3Drender --configs
arguments/video_dataset/Neu3D.py" --render_checkpoint path_to_checkpoint
```


## Evaluation

You can just run the following script to evaluate the model.

```python
#### for dynamic scene eval -d : output base folder -s scene name
python calc_metric.py -d './test/' -s flame_steak_sparse

#### for distractor static scene eval -d : output base folder -s scene name
python calc_metric_static.py -d './test/' -s patio_high 

```


## Related Work

We sincerely thank the authors of following papers and their fantastic works

[4DGaussians:4D Gaussian Splatting for Real-Time Dynamic Scene Rendering](https://guanjunwu.github.io/4dgs/)

[SpotLessSplats: Ignoring Distractors in 3D Gaussian Splatting](https://spotlesssplats.github.io)


## Citation

If you find this repository/work helpful in your research, welcome to cite our paper and give a â­.

```
@misc{wang2025degaussdynamicstaticdecompositiongaussian,
        title={DeGauss: Dynamic-Static Decomposition with Gaussian Splatting for Distractor-free 3D Reconstruction}, 
        author={Rui Wang and Quentin Lohmeyer and Mirko Meboldt and Siyu Tang},
        year={2025},
        eprint={2503.13176},
        archivePrefix={arXiv},
        primaryClass={cs.CV},
        url={https://arxiv.org/abs/2503.13176}, 
  }
    
```
